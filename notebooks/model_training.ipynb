{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Loan Risk Model Training\n",
                "This notebook handles the end-to-end pipeline for loan default prediction, including feature engineering, model selection, and hyperparameter optimization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "import shap\n",
                "import optuna\n",
                "import warnings\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, confusion_matrix, RocCurveDisplay, ConfusionMatrixDisplay\n",
                "import xgboost as xgb\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
                "print(\"Environment initialized.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load Dataset\n",
                "We use a subset of the LendingClub dataset for training to balance performance and memory usage."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    raw_data = pd.read_csv('../data/lending_club_accepted.csv', nrows=200000, low_memory=False)\n",
                "    print(f\"Loaded {len(raw_data)} rows from main dataset.\")\n",
                "except FileNotFoundError:\n",
                "    print(\"Source data missing. Looking for local sample...\")\n",
                "    raw_data = pd.read_csv('../data/lending_club_sample.csv')\n",
                "    print(f\"Using sample with {len(raw_data)} rows.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Feature Engineering\n",
                "Converting raw loan data into predictive features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def engineer_features(df):\n",
                "    df = df[df['loan_status'].isin(['Fully Paid', 'Charged Off', 'Default'])].copy()\n",
                "    df['target'] = df['loan_status'].apply(lambda x: 1 if x in ['Charged Off', 'Default'] else 0)\n",
                "    \n",
                "    # Clean employment history\n",
                "    df['emp_length'] = df['emp_length'].str.extract(r'(\\d+)').astype(float)\n",
                "    df['emp_length'] = df['emp_length'].fillna(df['emp_length'].median())\n",
                "    \n",
                "    # Time-based features\n",
                "    df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'], errors='coerce')\n",
                "    df['issue_d'] = pd.to_datetime(df['issue_d'], errors='coerce')\n",
                "    df['credit_history_length'] = (df['issue_d'] - df['earliest_cr_line']).dt.days / 365.25\n",
                "    \n",
                "    # Financial ratios\n",
                "    df['loan_to_income'] = df['loan_amnt'] / (df['annual_inc'] + 1)\n",
                "    df['interest_to_income'] = (df['installment'] * 12) / (df['annual_inc'] + 1)\n",
                "    df['utilization_efficiency'] = df['revol_util'] / (df['open_acc'] + 1)\n",
                "    \n",
                "    return df.drop(columns=['earliest_cr_line', 'issue_d'])\n",
                "\n",
                "df_clean = engineer_features(raw_data)\n",
                "print(\"Feature engineering complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Preprocessing Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "features = [\n",
                "    'loan_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_length',\n",
                "    'home_ownership', 'annual_inc', 'verification_status', 'purpose', 'dti', 'open_acc',\n",
                "    'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status',\n",
                "    'application_type', 'mort_acc', 'pub_rec_bankruptcies', 'credit_history_length',\n",
                "    'loan_to_income', 'interest_to_income', 'utilization_efficiency'\n",
                "]\n",
                "\n",
                "X = df_clean[features]\n",
                "y = df_clean['target']\n",
                "\n",
                "numeric_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
                "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
                "\n",
                "processor = ColumnTransformer([\n",
                "    ('num', StandardScaler(), numeric_cols),\n",
                "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
                "])\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
                "print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Final Model Training\n",
                "Training the optimized XGBoost classifier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optimized parameters\n",
                "params = {\n",
                "    'n_estimators': 800,\n",
                "    'learning_rate': 0.05,\n",
                "    'max_depth': 6,\n",
                "    'subsample': 0.8,\n",
                "    'colsample_bytree': 0.8,\n",
                "    'scale_pos_weight': 3,  # Adjusting for class imbalance\n",
                "    'random_state': 42,\n",
                "    'eval_metric': 'auc'\n",
                "}\n",
                "\n",
                "final_pipe = Pipeline([('preprocessor', processor), ('classifier', xgb.XGBClassifier(**params))])\n",
                "final_pipe.fit(X_train, y_train)\n",
                "print(\"Model training complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Performance Metrics\n",
                "Evaluating accuracy and model robustness."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = final_pipe.predict(X_test)\n",
                "y_proba = final_pipe.predict_proba(X_test)[:, 1]\n",
                "\n",
                "print(f\"--- Classification Report ---\")\n",
                "print(classification_report(y_test, y_pred))\n",
                "\n",
                "print(f\"Overall Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
                "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visual Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
                "\n",
                "# 1. ROC Curve\n",
                "RocCurveDisplay.from_estimator(final_pipe, X_test, y_test, ax=ax[0], color='#da7756')\n",
                "ax[0].set_title(\"Receiver Operating Characteristic (ROC)\")\n",
                "ax[0].plot([0, 1], [0, 1], linestyle='--', color='grey')\n",
                "\n",
                "# 2. Confusion Matrix\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', ax=ax[1])\n",
                "ax[1].set_title(\"Confusion Matrix\")\n",
                "ax[1].set_xlabel(\"Predicted Label\")\n",
                "ax[1].set_ylabel(\"True Label\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Feature Importance\n",
                "Identifying the top predictors of default."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "feature_names = final_pipe.named_steps['preprocessor'].get_feature_names_out()\n",
                "importances = final_pipe.named_steps['classifier'].feature_importances_\n",
                "indices = np.argsort(importances)[-15:]\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "plt.title('Top 15 Feature Importances')\n",
                "plt.barh(range(len(indices)), importances[indices], color='#da7756', align='center')\n",
                "plt.yticks(range(len(indices)), [feature_names[i].split('__')[-1] for i in indices])\n",
                "plt.xlabel('Relative Importance')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Export Artifacts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "joblib.dump(final_pipe, '../models/best_model.joblib')\n",
                "joblib.dump(feature_names, '../models/processed_feature_names.joblib')\n",
                "print(\"Artifacts exported to /models/\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}